{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ambiente configurado para treinamento local em um PC com Placa de V√≠deo Nvidia RTX-3060 12GB\n",
    "\n",
    "## Utilizando miniconda, instalado em um Linux Ubuntu conforme orienta√ß√µes do link: https://docs.anaconda.com/miniconda/\n",
    "## Utilizando miniconda para cria√ß√£o do ambiente do unsloth conforme orienta√ß√£o no link: https://docs.unsloth.ai/get-started/installation/conda-install\n",
    "\n",
    "## >> Para configurar o ambiente, remova o coment√°rio (\"##\") e execute os comandos. Lembre-se de instalar o miniconda previamente\n",
    "\n",
    "#!pip install nbformat\n",
    "#!conda install -c conda-forge ipywidgets\n",
    "#!conda create --name unsloth_env python=3.10 pytorch-cuda=12.1 pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers -y\n",
    "#!conda activate unsloth_env\n",
    "#!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "#!pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "2.4.1\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "import torch; \n",
    "\n",
    "import datasets\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id Model: 1 - Model Name: unsloth/tinyllama\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "model_name, raw_model, tokenizer = helper.get_model_by_id(1, max_seq_length, dtype, load_in_4bit)  ## \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func_train(examples):        \n",
    "    inputs       = examples['title']\n",
    "    outputs      = examples['content']\n",
    "    texts = []\n",
    "    #for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = helper.alpaca_prompt.format(input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.9 patched 22 layers with 22 QKV layers, 22 O layers and 22 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = helper.get_fast_language_model(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['uid', 'title', 'content', 'text'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_csv('../data/trn_sample.csv', sep=';')\n",
    "dataset = dataset.map(formatting_prompts_func_train, batched = True,)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a04ef9933c54b779737f1d2b7733259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 10,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        #max_steps = 60,\n",
    "        #learning_rate = 2e-4,\n",
    "        learning_rate = 3e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3060. Max memory = 11.65 GB.\n",
      "0.787 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "start_gpu_memory, max_memory = helper.print_start_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 16 | Total steps = 62\n",
      " \"-____-\"     Number of trainable parameters = 12,615,680\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44778ffcb7045efa883a76b0a54f43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6714, 'grad_norm': 16.946605682373047, 'learning_rate': 2.9999999999999997e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4999, 'grad_norm': 15.496505737304688, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4363, 'grad_norm': 8.58876895904541, 'learning_rate': 8.999999999999999e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5097, 'grad_norm': 5.471931457519531, 'learning_rate': 0.00011999999999999999, 'epoch': 0.06}\n",
      "{'loss': 3.0741, 'grad_norm': 3.6497642993927, 'learning_rate': 0.00015, 'epoch': 0.08}\n",
      "{'loss': 2.8615, 'grad_norm': 6.896556377410889, 'learning_rate': 0.00017999999999999998, 'epoch': 0.1}\n",
      "{'loss': 2.7431, 'grad_norm': 7.148976802825928, 'learning_rate': 0.00020999999999999998, 'epoch': 0.11}\n",
      "{'loss': 2.5746, 'grad_norm': 3.7633118629455566, 'learning_rate': 0.00023999999999999998, 'epoch': 0.13}\n",
      "{'loss': 2.3007, 'grad_norm': 11.939837455749512, 'learning_rate': 0.00027, 'epoch': 0.14}\n",
      "{'loss': 2.1797, 'grad_norm': 4.596930027008057, 'learning_rate': 0.0003, 'epoch': 0.16}\n",
      "{'loss': 2.0304, 'grad_norm': 3.6026155948638916, 'learning_rate': 0.0002942307692307692, 'epoch': 0.18}\n",
      "{'loss': 2.0119, 'grad_norm': 2.2551069259643555, 'learning_rate': 0.00028846153846153843, 'epoch': 0.19}\n",
      "{'loss': 2.1728, 'grad_norm': 60.63972854614258, 'learning_rate': 0.00028269230769230764, 'epoch': 0.21}\n",
      "{'loss': 1.9057, 'grad_norm': 1.3828376531600952, 'learning_rate': 0.0002769230769230769, 'epoch': 0.22}\n",
      "{'loss': 2.0755, 'grad_norm': 1.3198726177215576, 'learning_rate': 0.00027115384615384615, 'epoch': 0.24}\n",
      "{'loss': 1.9641, 'grad_norm': 1.3546169996261597, 'learning_rate': 0.00026538461538461536, 'epoch': 0.26}\n",
      "{'loss': 1.9216, 'grad_norm': 0.9488552212715149, 'learning_rate': 0.0002596153846153846, 'epoch': 0.27}\n",
      "{'loss': 1.8398, 'grad_norm': 1.1268318891525269, 'learning_rate': 0.0002538461538461538, 'epoch': 0.29}\n",
      "{'loss': 1.8326, 'grad_norm': 1.0250475406646729, 'learning_rate': 0.000248076923076923, 'epoch': 0.3}\n",
      "{'loss': 1.876, 'grad_norm': 0.9514247179031372, 'learning_rate': 0.0002423076923076923, 'epoch': 0.32}\n",
      "{'loss': 1.7711, 'grad_norm': 0.8888469338417053, 'learning_rate': 0.0002365384615384615, 'epoch': 0.34}\n",
      "{'loss': 1.82, 'grad_norm': 1.3065216541290283, 'learning_rate': 0.00023076923076923076, 'epoch': 0.35}\n",
      "{'loss': 1.8662, 'grad_norm': 0.9594411849975586, 'learning_rate': 0.000225, 'epoch': 0.37}\n",
      "{'loss': 1.9238, 'grad_norm': 0.9701480269432068, 'learning_rate': 0.0002192307692307692, 'epoch': 0.38}\n",
      "{'loss': 1.6908, 'grad_norm': 0.9015830159187317, 'learning_rate': 0.00021346153846153845, 'epoch': 0.4}\n",
      "{'loss': 1.6169, 'grad_norm': 0.9817038774490356, 'learning_rate': 0.00020769230769230766, 'epoch': 0.42}\n",
      "{'loss': 1.5745, 'grad_norm': 0.8992224335670471, 'learning_rate': 0.00020192307692307691, 'epoch': 0.43}\n",
      "{'loss': 2.1161, 'grad_norm': 0.9075552821159363, 'learning_rate': 0.00019615384615384615, 'epoch': 0.45}\n",
      "{'loss': 1.4913, 'grad_norm': 0.8798759579658508, 'learning_rate': 0.00019038461538461535, 'epoch': 0.46}\n",
      "{'loss': 1.9195, 'grad_norm': 0.9924511313438416, 'learning_rate': 0.0001846153846153846, 'epoch': 0.48}\n",
      "{'loss': 2.0291, 'grad_norm': 0.8278621435165405, 'learning_rate': 0.00017884615384615384, 'epoch': 0.5}\n",
      "{'loss': 1.7777, 'grad_norm': 1.1042436361312866, 'learning_rate': 0.00017307692307692304, 'epoch': 0.51}\n",
      "{'loss': 1.7805, 'grad_norm': 0.8344728946685791, 'learning_rate': 0.0001673076923076923, 'epoch': 0.53}\n",
      "{'loss': 2.1009, 'grad_norm': 0.8183008432388306, 'learning_rate': 0.00016153846153846153, 'epoch': 0.54}\n",
      "{'loss': 1.9183, 'grad_norm': 0.9278538823127747, 'learning_rate': 0.00015576923076923076, 'epoch': 0.56}\n",
      "{'loss': 1.7865, 'grad_norm': 0.801946759223938, 'learning_rate': 0.00015, 'epoch': 0.58}\n",
      "{'loss': 1.8113, 'grad_norm': 0.8085460662841797, 'learning_rate': 0.00014423076923076922, 'epoch': 0.59}\n",
      "{'loss': 1.5163, 'grad_norm': 0.9649940133094788, 'learning_rate': 0.00013846153846153845, 'epoch': 0.61}\n",
      "{'loss': 1.6831, 'grad_norm': 0.934922993183136, 'learning_rate': 0.00013269230769230768, 'epoch': 0.62}\n",
      "{'loss': 1.9742, 'grad_norm': 0.8315278887748718, 'learning_rate': 0.0001269230769230769, 'epoch': 0.64}\n",
      "{'loss': 2.0854, 'grad_norm': 0.9211772084236145, 'learning_rate': 0.00012115384615384615, 'epoch': 0.66}\n",
      "{'loss': 1.7556, 'grad_norm': 0.8868424892425537, 'learning_rate': 0.00011538461538461538, 'epoch': 0.67}\n",
      "{'loss': 2.0011, 'grad_norm': 0.7985438108444214, 'learning_rate': 0.0001096153846153846, 'epoch': 0.69}\n",
      "{'loss': 1.5802, 'grad_norm': 0.9713122248649597, 'learning_rate': 0.00010384615384615383, 'epoch': 0.7}\n",
      "{'loss': 1.8932, 'grad_norm': 0.8996726870536804, 'learning_rate': 9.807692307692307e-05, 'epoch': 0.72}\n",
      "{'loss': 2.0417, 'grad_norm': 0.8361426591873169, 'learning_rate': 9.23076923076923e-05, 'epoch': 0.74}\n",
      "{'loss': 1.8085, 'grad_norm': 0.88197261095047, 'learning_rate': 8.653846153846152e-05, 'epoch': 0.75}\n",
      "{'loss': 2.0712, 'grad_norm': 0.7756332159042358, 'learning_rate': 8.076923076923076e-05, 'epoch': 0.77}\n",
      "{'loss': 1.9332, 'grad_norm': 0.746718168258667, 'learning_rate': 7.5e-05, 'epoch': 0.78}\n",
      "{'loss': 1.919, 'grad_norm': 0.9104785919189453, 'learning_rate': 6.923076923076922e-05, 'epoch': 0.8}\n",
      "{'loss': 2.076, 'grad_norm': 0.8029929399490356, 'learning_rate': 6.346153846153845e-05, 'epoch': 0.82}\n",
      "{'loss': 1.9068, 'grad_norm': 0.8727464079856873, 'learning_rate': 5.769230769230769e-05, 'epoch': 0.83}\n",
      "{'loss': 1.9567, 'grad_norm': 0.7771033048629761, 'learning_rate': 5.1923076923076914e-05, 'epoch': 0.85}\n",
      "{'loss': 1.7648, 'grad_norm': 0.8252093195915222, 'learning_rate': 4.615384615384615e-05, 'epoch': 0.86}\n",
      "{'loss': 1.9085, 'grad_norm': 0.7794281244277954, 'learning_rate': 4.038461538461538e-05, 'epoch': 0.88}\n",
      "{'loss': 1.7805, 'grad_norm': 0.8592113852500916, 'learning_rate': 3.461538461538461e-05, 'epoch': 0.9}\n",
      "{'loss': 1.8949, 'grad_norm': 0.8211455345153809, 'learning_rate': 2.8846153846153845e-05, 'epoch': 0.91}\n",
      "{'loss': 2.0835, 'grad_norm': 0.7774057984352112, 'learning_rate': 2.3076923076923076e-05, 'epoch': 0.93}\n",
      "{'loss': 1.875, 'grad_norm': 0.8709515333175659, 'learning_rate': 1.7307692307692306e-05, 'epoch': 0.94}\n",
      "{'loss': 1.7048, 'grad_norm': 0.8796751499176025, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.96}\n",
      "{'loss': 1.9152, 'grad_norm': 0.8289979696273804, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.98}\n",
      "{'loss': 1.9348, 'grad_norm': 0.7876572608947754, 'learning_rate': 0.0, 'epoch': 0.99}\n",
      "{'train_runtime': 175.9372, 'train_samples_per_second': 5.684, 'train_steps_per_second': 0.352, 'train_loss': 2.057101147790109, 'epoch': 0.99}\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.9372 seconds used for training.\n",
      "2.93 minutes used for training.\n",
      "Peak reserved memory = 3.619 GB.\n",
      "Peak reserved memory for training = 2.832 GB.\n",
      "Peak reserved memory % of max memory = 31.064 %.\n",
      "Peak reserved memory for training % of max memory = 24.309 %.\n"
     ]
    }
   ],
   "source": [
    "helper.print_final_memory_usage(start_gpu_memory, max_memory, trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da predi√ß√£o para o t√≠tulo: [The Gentle Birth Method The Monthbymonth Jeyarani Way Programme]\n",
      "\n",
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Based on title of a product, get the real description for the follow product.\n",
      "\n",
      "### Input:\n",
      "The Gentle Birth Method The Monthbymonth Jeyarani Way Programme\n",
      "\n",
      "### Response:\n",
      "The Gentle Birth Method is a comprehensive programme for women who want to have a gentle birth. It is based on the principles of the ancient Indian Ayurvedic system of healthcare. The programme is designed to help women prepare for labour and to give them the knowledge and confidence to have a gentle birth.</s>\n",
      "Resultado da predi√ß√£o para o t√≠tulo: [Farther Shores Exploring How NearDeath Kundalini and Mystical Experiences Can Transform Ordinary Lives]\n",
      "\n",
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Based on title of a product, get the real description for the follow product.\n",
      "\n",
      "### Input:\n",
      "Farther Shores Exploring How NearDeath Kundalini and Mystical Experiences Can Transform Ordinary Lives\n",
      "\n",
      "### Response:\n",
      "This is a book that will appeal to anyone who has ever been touched by the mystical. It is a book that will help you to understand the mysteries of the universe and the mysteries of your own life. It is a book that will help you to understand the power of the mind and the power of the heart. It is a book that will help you to understand the power of the universe. It is a book that will help you to understand the power of your own mind. It is a book that will help you to understand the power of your own heart. It is a book that will help you to understand the power\n",
      "Resultado da predi√ß√£o para o t√≠tulo: [Millwrights and Mechanics Guide Audel]\n",
      "\n",
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Based on title of a product, get the real description for the follow product.\n",
      "\n",
      "### Input:\n",
      "Millwrights and Mechanics Guide Audel\n",
      "\n",
      "### Response:\n",
      "This is a comprehensive guide to the world of millwrighting and mechanics. It is a practical guide to the skills and techniques of the trade and is intended to be a reference for the millwright and mechanic.</s>\n",
      "Resultado da predi√ß√£o para o t√≠tulo: [The Wall Images and Offerings from the Vietnam Veterans Memorial]\n",
      "\n",
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Based on title of a product, get the real description for the follow product.\n",
      "\n",
      "### Input:\n",
      "The Wall Images and Offerings from the Vietnam Veterans Memorial\n",
      "\n",
      "### Response:\n",
      "The Wall is a monument to the 18,000 Americans who died in the Vietnam War. It is also a memorial to the 1.5 million who served in the war and to the 1.5 million who have died since. The Wall is a place of remembrance and a place of hope. The Wall is a place of contemplation and a place of action. The Wall is a place of love and a place of hate. The Wall is a place of hope and a place of despair. The Wall is a place of peace and a place of war. The Wall is a place\n",
      "Resultado da predi√ß√£o para o t√≠tulo: [Once There Was a Boy]\n",
      "\n",
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Based on title of a product, get the real description for the follow product.\n",
      "\n",
      "### Input:\n",
      "Once There Was a Boy\n",
      "\n",
      "### Response:\n",
      "A beautifully written and moving story of love and loss. The Times A beautifully written and moving story of love and loss. The Times A beautifully written and moving story of love and loss. The Times</s>\n"
     ]
    }
   ],
   "source": [
    "# Teste do modelo depois do treinamento\n",
    "\n",
    "df = dataset.to_pandas().sample(frac=1).head(5).copy()\n",
    "for _, row in df.iterrows():\n",
    "  title = row['title']\n",
    "  print(f\"Resultado da predi√ß√£o para o t√≠tulo: [{title}]\\n\")\n",
    "  helper.predict_text_streamer(model, tokenizer, title)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tinyllama/tokenizer_config.json',\n",
       " 'tinyllama/special_tokens_map.json',\n",
       " 'tinyllama/tokenizer.model',\n",
       " 'tinyllama/added_tokens.json',\n",
       " 'tinyllama/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('tinyllama') # Local saving\n",
    "tokenizer.save_pretrained('tinyllama')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
