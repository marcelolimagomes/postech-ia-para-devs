{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ambiente configurado para treinamento local em um PC com Placa de V√≠deo Nvidia RTX-3060 12GB\n",
    "\n",
    "## Utilizando miniconda, instalado em um Linux Ubuntu conforme orienta√ß√µes do link: https://docs.anaconda.com/miniconda/\n",
    "## Utilizando miniconda para cria√ß√£o do ambiente do unsloth conforme orienta√ß√£o no link: https://docs.unsloth.ai/get-started/installation/conda-install\n",
    "\n",
    "## >> Para configurar o ambiente, remova o coment√°rio (\"##\") e execute os comandos. Lembre-se de instalar o miniconda previamente\n",
    "\n",
    "#!pip install nbformat\n",
    "#!conda install -c conda-forge ipywidgets\n",
    "#!conda create --name unsloth_env python=3.10 pytorch-cuda=12.1 pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers -y\n",
    "#!conda activate unsloth_env\n",
    "#!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "#!pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "2.4.1\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "import torch; \n",
    "\n",
    "import datasets\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id Model: 0 - Model Name: unsloth/Meta-Llama-3.1-8B\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "model_name, raw_model, tokenizer = helper.get_model_by_id(0, max_seq_length, dtype, load_in_4bit)  ## \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func_train(examples):        \n",
    "    inputs       = examples['title']\n",
    "    outputs      = examples['content']\n",
    "    texts = []\n",
    "    #for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = helper.alpaca_prompt.format(input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = helper.get_fast_language_model(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a175cd75f38d4294ac791d9f759b3704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e524024ae94698b9a37251fe91f905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content', 'text'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_csv('../data/trn_sample.csv', sep=';')\n",
    "dataset = dataset.map(formatting_prompts_func_train, batched = True,)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0559e1bd3da4960a4d42764379fd486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        #max_steps = 60,\n",
    "        #learning_rate = 2e-4,\n",
    "        learning_rate = 3e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3060. Max memory = 11.65 GB.\n",
      "5.984 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "start_gpu_memory, max_memory = helper.print_start_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 10,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 1,250\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b41755d3694a198406dd8c1a6c49b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.92, 'grad_norm': 2.6884117126464844, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.0}\n",
      "{'loss': 3.0875, 'grad_norm': 1.964647889137268, 'learning_rate': 0.00011999999999999999, 'epoch': 0.0}\n",
      "{'loss': 2.9715, 'grad_norm': 2.1089975833892822, 'learning_rate': 0.00017999999999999998, 'epoch': 0.0}\n",
      "{'loss': 3.0611, 'grad_norm': 4.286407470703125, 'learning_rate': 0.00023999999999999998, 'epoch': 0.0}\n",
      "{'loss': 2.7159, 'grad_norm': 1.6686680316925049, 'learning_rate': 0.0003, 'epoch': 0.0}\n",
      "{'loss': 2.0985, 'grad_norm': 1.9944469928741455, 'learning_rate': 0.0002997590361445783, 'epoch': 0.0}\n",
      "{'loss': 2.3526, 'grad_norm': 5.69419527053833, 'learning_rate': 0.0002995180722891566, 'epoch': 0.01}\n",
      "{'loss': 2.2694, 'grad_norm': 2.912416696548462, 'learning_rate': 0.00029927710843373495, 'epoch': 0.01}\n",
      "{'loss': 2.3342, 'grad_norm': 1.6300982236862183, 'learning_rate': 0.0002990361445783132, 'epoch': 0.01}\n",
      "{'loss': 2.1471, 'grad_norm': 1.4643645286560059, 'learning_rate': 0.00029879518072289154, 'epoch': 0.01}\n",
      "{'loss': 2.3331, 'grad_norm': 1.2870190143585205, 'learning_rate': 0.00029855421686746987, 'epoch': 0.01}\n",
      "{'loss': 1.9264, 'grad_norm': 1.8726701736450195, 'learning_rate': 0.00029831325301204814, 'epoch': 0.01}\n",
      "{'loss': 1.8983, 'grad_norm': 1.2844727039337158, 'learning_rate': 0.00029807228915662646, 'epoch': 0.01}\n",
      "{'loss': 2.3186, 'grad_norm': 1.128799319267273, 'learning_rate': 0.0002978313253012048, 'epoch': 0.01}\n",
      "{'loss': 1.9483, 'grad_norm': 1.5885870456695557, 'learning_rate': 0.0002975903614457831, 'epoch': 0.01}\n",
      "{'loss': 2.3292, 'grad_norm': 1.33074951171875, 'learning_rate': 0.00029734939759036143, 'epoch': 0.01}\n",
      "{'loss': 1.8476, 'grad_norm': 1.4968657493591309, 'learning_rate': 0.00029710843373493976, 'epoch': 0.01}\n",
      "{'loss': 2.3607, 'grad_norm': 1.61651611328125, 'learning_rate': 0.0002968674698795181, 'epoch': 0.01}\n",
      "{'loss': 2.3294, 'grad_norm': 1.351639986038208, 'learning_rate': 0.00029662650602409635, 'epoch': 0.02}\n",
      "{'loss': 2.1247, 'grad_norm': 3.0324316024780273, 'learning_rate': 0.0002963855421686747, 'epoch': 0.02}\n",
      "{'loss': 2.2203, 'grad_norm': 1.2774606943130493, 'learning_rate': 0.000296144578313253, 'epoch': 0.02}\n",
      "{'loss': 2.2867, 'grad_norm': 1.3565291166305542, 'learning_rate': 0.00029590361445783127, 'epoch': 0.02}\n",
      "{'loss': 2.2518, 'grad_norm': 1.5095819234848022, 'learning_rate': 0.0002956626506024096, 'epoch': 0.02}\n",
      "{'loss': 1.881, 'grad_norm': 1.6831200122833252, 'learning_rate': 0.0002954216867469879, 'epoch': 0.02}\n",
      "{'loss': 2.2424, 'grad_norm': 1.2440310716629028, 'learning_rate': 0.00029518072289156624, 'epoch': 0.02}\n",
      "{'loss': 2.0888, 'grad_norm': 1.3990353345870972, 'learning_rate': 0.00029493975903614457, 'epoch': 0.02}\n",
      "{'loss': 2.0736, 'grad_norm': 1.9869921207427979, 'learning_rate': 0.0002946987951807229, 'epoch': 0.02}\n",
      "{'loss': 2.1222, 'grad_norm': 1.5896657705307007, 'learning_rate': 0.00029445783132530116, 'epoch': 0.02}\n",
      "{'loss': 2.1994, 'grad_norm': 3.902447462081909, 'learning_rate': 0.0002942168674698795, 'epoch': 0.02}\n",
      "{'loss': 2.5169, 'grad_norm': 3.2878851890563965, 'learning_rate': 0.0002939759036144578, 'epoch': 0.02}\n",
      "{'loss': 2.1253, 'grad_norm': 1.5985037088394165, 'learning_rate': 0.00029373493975903614, 'epoch': 0.02}\n",
      "{'loss': 2.1945, 'grad_norm': 1.1112945079803467, 'learning_rate': 0.0002934939759036144, 'epoch': 0.03}\n",
      "{'loss': 2.1599, 'grad_norm': 1.248599886894226, 'learning_rate': 0.00029325301204819273, 'epoch': 0.03}\n",
      "{'loss': 2.2074, 'grad_norm': 1.4425697326660156, 'learning_rate': 0.00029301204819277106, 'epoch': 0.03}\n",
      "{'loss': 2.4368, 'grad_norm': 1.2161972522735596, 'learning_rate': 0.0002927710843373494, 'epoch': 0.03}\n",
      "{'loss': 2.159, 'grad_norm': 1.3397037982940674, 'learning_rate': 0.0002925301204819277, 'epoch': 0.03}\n",
      "{'loss': 2.1796, 'grad_norm': 1.2326706647872925, 'learning_rate': 0.000292289156626506, 'epoch': 0.03}\n",
      "{'loss': 2.2667, 'grad_norm': 1.3486883640289307, 'learning_rate': 0.0002920481927710843, 'epoch': 0.03}\n",
      "{'loss': 2.0714, 'grad_norm': 1.2877686023712158, 'learning_rate': 0.0002918072289156626, 'epoch': 0.03}\n",
      "{'loss': 1.8399, 'grad_norm': 16.666627883911133, 'learning_rate': 0.00029156626506024095, 'epoch': 0.03}\n",
      "{'loss': 2.5225, 'grad_norm': 1.1862796545028687, 'learning_rate': 0.00029132530120481927, 'epoch': 0.03}\n",
      "{'loss': 2.1355, 'grad_norm': 1.184198260307312, 'learning_rate': 0.00029108433734939754, 'epoch': 0.03}\n",
      "{'loss': 2.3207, 'grad_norm': 1.0905978679656982, 'learning_rate': 0.00029084337349397587, 'epoch': 0.03}\n",
      "{'loss': 2.2625, 'grad_norm': 1.2793747186660767, 'learning_rate': 0.0002906024096385542, 'epoch': 0.04}\n",
      "{'loss': 2.1006, 'grad_norm': 1.1871637105941772, 'learning_rate': 0.0002903614457831325, 'epoch': 0.04}\n",
      "{'loss': 2.056, 'grad_norm': 1.4130009412765503, 'learning_rate': 0.0002901204819277108, 'epoch': 0.04}\n",
      "{'loss': 2.2079, 'grad_norm': 1.3672653436660767, 'learning_rate': 0.0002898795180722891, 'epoch': 0.04}\n",
      "{'loss': 2.3498, 'grad_norm': 1.0895049571990967, 'learning_rate': 0.00028963855421686743, 'epoch': 0.04}\n",
      "{'loss': 2.0884, 'grad_norm': 1.3334691524505615, 'learning_rate': 0.00028939759036144576, 'epoch': 0.04}\n",
      "{'loss': 2.1986, 'grad_norm': 1.277105689048767, 'learning_rate': 0.0002891566265060241, 'epoch': 0.04}\n",
      "{'loss': 1.947, 'grad_norm': 1.2189489603042603, 'learning_rate': 0.0002889156626506024, 'epoch': 0.04}\n",
      "{'loss': 2.3948, 'grad_norm': 1.3553314208984375, 'learning_rate': 0.0002886746987951807, 'epoch': 0.04}\n",
      "{'loss': 2.196, 'grad_norm': 1.1789023876190186, 'learning_rate': 0.000288433734939759, 'epoch': 0.04}\n",
      "{'loss': 2.2075, 'grad_norm': 1.1610246896743774, 'learning_rate': 0.0002881927710843373, 'epoch': 0.04}\n",
      "{'loss': 2.0679, 'grad_norm': 1.479959487915039, 'learning_rate': 0.0002879518072289156, 'epoch': 0.04}\n",
      "{'loss': 1.8907, 'grad_norm': 1.3720871210098267, 'learning_rate': 0.0002877108433734939, 'epoch': 0.04}\n",
      "{'loss': 2.22, 'grad_norm': 1.148394227027893, 'learning_rate': 0.00028746987951807225, 'epoch': 0.05}\n",
      "{'loss': 2.0097, 'grad_norm': 1.1787644624710083, 'learning_rate': 0.00028722891566265057, 'epoch': 0.05}\n",
      "{'loss': 2.2292, 'grad_norm': 1.4025590419769287, 'learning_rate': 0.0002869879518072289, 'epoch': 0.05}\n",
      "{'loss': 2.1734, 'grad_norm': 1.270859956741333, 'learning_rate': 0.0002867469879518072, 'epoch': 0.05}\n",
      "{'loss': 2.079, 'grad_norm': 1.5066522359848022, 'learning_rate': 0.00028650602409638554, 'epoch': 0.05}\n",
      "{'loss': 2.2571, 'grad_norm': 1.30948805809021, 'learning_rate': 0.0002862650602409638, 'epoch': 0.05}\n",
      "{'loss': 2.3383, 'grad_norm': 1.5712171792984009, 'learning_rate': 0.00028602409638554214, 'epoch': 0.05}\n",
      "{'loss': 1.8889, 'grad_norm': 1.6867799758911133, 'learning_rate': 0.00028578313253012046, 'epoch': 0.05}\n",
      "{'loss': 1.8023, 'grad_norm': 1.3205935955047607, 'learning_rate': 0.00028554216867469873, 'epoch': 0.05}\n",
      "{'loss': 2.1357, 'grad_norm': 1.363808274269104, 'learning_rate': 0.00028530120481927706, 'epoch': 0.05}\n",
      "{'loss': 2.4574, 'grad_norm': 1.171513319015503, 'learning_rate': 0.0002850602409638554, 'epoch': 0.05}\n",
      "{'loss': 2.0946, 'grad_norm': 1.5916228294372559, 'learning_rate': 0.0002848192771084337, 'epoch': 0.05}\n",
      "{'loss': 2.0883, 'grad_norm': 1.5382065773010254, 'learning_rate': 0.00028457831325301203, 'epoch': 0.06}\n",
      "{'loss': 2.2629, 'grad_norm': 1.3164764642715454, 'learning_rate': 0.00028433734939759035, 'epoch': 0.06}\n",
      "{'loss': 2.1528, 'grad_norm': 1.732245683670044, 'learning_rate': 0.0002840963855421687, 'epoch': 0.06}\n",
      "{'loss': 2.1642, 'grad_norm': 1.262610673904419, 'learning_rate': 0.000283855421686747, 'epoch': 0.06}\n",
      "{'loss': 2.035, 'grad_norm': 1.3258522748947144, 'learning_rate': 0.00028361445783132527, 'epoch': 0.06}\n",
      "{'loss': 1.9911, 'grad_norm': 1.4121475219726562, 'learning_rate': 0.0002833734939759036, 'epoch': 0.06}\n",
      "{'loss': 2.3093, 'grad_norm': 1.8020082712173462, 'learning_rate': 0.00028313253012048187, 'epoch': 0.06}\n",
      "{'loss': 2.0882, 'grad_norm': 0.9595496654510498, 'learning_rate': 0.0002828915662650602, 'epoch': 0.06}\n",
      "{'loss': 1.927, 'grad_norm': 1.295935869216919, 'learning_rate': 0.0002826506024096385, 'epoch': 0.06}\n",
      "{'loss': 2.0599, 'grad_norm': 1.4447135925292969, 'learning_rate': 0.00028240963855421684, 'epoch': 0.06}\n",
      "{'loss': 2.1743, 'grad_norm': 1.2894757986068726, 'learning_rate': 0.00028216867469879516, 'epoch': 0.06}\n",
      "{'loss': 2.2256, 'grad_norm': 1.3581539392471313, 'learning_rate': 0.0002819277108433735, 'epoch': 0.06}\n",
      "{'loss': 2.3781, 'grad_norm': 1.2006508111953735, 'learning_rate': 0.0002816867469879518, 'epoch': 0.06}\n",
      "{'loss': 2.1062, 'grad_norm': 1.3353599309921265, 'learning_rate': 0.00028144578313253014, 'epoch': 0.07}\n",
      "{'loss': 2.2201, 'grad_norm': 1.3490898609161377, 'learning_rate': 0.0002812048192771084, 'epoch': 0.07}\n",
      "{'loss': 2.5088, 'grad_norm': 1.2164595127105713, 'learning_rate': 0.00028096385542168673, 'epoch': 0.07}\n",
      "{'loss': 2.4485, 'grad_norm': 1.1728588342666626, 'learning_rate': 0.000280722891566265, 'epoch': 0.07}\n",
      "{'loss': 2.4282, 'grad_norm': 1.2073969841003418, 'learning_rate': 0.0002804819277108433, 'epoch': 0.07}\n",
      "{'loss': 2.0581, 'grad_norm': 1.1044790744781494, 'learning_rate': 0.00028024096385542165, 'epoch': 0.07}\n",
      "{'loss': 2.1384, 'grad_norm': 1.2899580001831055, 'learning_rate': 0.00028, 'epoch': 0.07}\n",
      "{'loss': 2.1701, 'grad_norm': 1.1752291917800903, 'learning_rate': 0.0002797590361445783, 'epoch': 0.07}\n",
      "{'loss': 2.3973, 'grad_norm': 1.3410754203796387, 'learning_rate': 0.0002795180722891566, 'epoch': 0.07}\n",
      "{'loss': 2.0211, 'grad_norm': 1.4917519092559814, 'learning_rate': 0.00027927710843373495, 'epoch': 0.07}\n",
      "{'loss': 2.2124, 'grad_norm': 1.2022250890731812, 'learning_rate': 0.0002790361445783132, 'epoch': 0.07}\n",
      "{'loss': 2.304, 'grad_norm': 1.3608555793762207, 'learning_rate': 0.00027879518072289154, 'epoch': 0.07}\n",
      "{'loss': 1.9987, 'grad_norm': 1.606737732887268, 'learning_rate': 0.00027855421686746987, 'epoch': 0.08}\n",
      "{'loss': 2.2328, 'grad_norm': 1.3510034084320068, 'learning_rate': 0.0002783132530120482, 'epoch': 0.08}\n",
      "{'loss': 2.0594, 'grad_norm': 1.340490698814392, 'learning_rate': 0.00027807228915662646, 'epoch': 0.08}\n",
      "{'loss': 2.2223, 'grad_norm': 1.2082669734954834, 'learning_rate': 0.0002778313253012048, 'epoch': 0.08}\n",
      "{'loss': 2.1986, 'grad_norm': 1.116823434829712, 'learning_rate': 0.0002775903614457831, 'epoch': 0.08}\n",
      "{'loss': 2.3605, 'grad_norm': 1.2826961278915405, 'learning_rate': 0.00027734939759036144, 'epoch': 0.08}\n",
      "{'loss': 2.2059, 'grad_norm': 1.3043848276138306, 'learning_rate': 0.00027710843373493976, 'epoch': 0.08}\n",
      "{'loss': 2.1093, 'grad_norm': 1.2867506742477417, 'learning_rate': 0.00027686746987951803, 'epoch': 0.08}\n",
      "{'loss': 2.3192, 'grad_norm': 1.231227993965149, 'learning_rate': 0.00027662650602409635, 'epoch': 0.08}\n",
      "{'loss': 2.1814, 'grad_norm': 1.2811102867126465, 'learning_rate': 0.0002763855421686747, 'epoch': 0.08}\n",
      "{'loss': 2.2154, 'grad_norm': 1.440711498260498, 'learning_rate': 0.000276144578313253, 'epoch': 0.08}\n",
      "{'loss': 1.9082, 'grad_norm': 1.4740962982177734, 'learning_rate': 0.00027590361445783133, 'epoch': 0.08}\n",
      "{'loss': 2.1919, 'grad_norm': 1.3757822513580322, 'learning_rate': 0.0002756626506024096, 'epoch': 0.08}\n",
      "{'loss': 2.1301, 'grad_norm': 1.4434032440185547, 'learning_rate': 0.0002754216867469879, 'epoch': 0.09}\n",
      "{'loss': 2.3804, 'grad_norm': 1.2002465724945068, 'learning_rate': 0.00027518072289156625, 'epoch': 0.09}\n",
      "{'loss': 2.0582, 'grad_norm': 2.1222569942474365, 'learning_rate': 0.00027493975903614457, 'epoch': 0.09}\n",
      "{'loss': 2.1023, 'grad_norm': 1.4653246402740479, 'learning_rate': 0.00027469879518072284, 'epoch': 0.09}\n",
      "{'loss': 2.0818, 'grad_norm': 2.446138858795166, 'learning_rate': 0.00027445783132530117, 'epoch': 0.09}\n",
      "{'loss': 2.284, 'grad_norm': 1.3704994916915894, 'learning_rate': 0.0002742168674698795, 'epoch': 0.09}\n",
      "{'loss': 2.1209, 'grad_norm': 1.4717859029769897, 'learning_rate': 0.0002739759036144578, 'epoch': 0.09}\n",
      "{'loss': 2.0228, 'grad_norm': 1.1492564678192139, 'learning_rate': 0.00027373493975903614, 'epoch': 0.09}\n",
      "{'loss': 2.1317, 'grad_norm': 1.4239462614059448, 'learning_rate': 0.00027349397590361446, 'epoch': 0.09}\n",
      "{'loss': 2.2399, 'grad_norm': 1.3778477907180786, 'learning_rate': 0.00027325301204819273, 'epoch': 0.09}\n",
      "{'loss': 2.1488, 'grad_norm': 1.3598427772521973, 'learning_rate': 0.00027301204819277106, 'epoch': 0.09}\n",
      "{'loss': 2.3611, 'grad_norm': 1.147537112236023, 'learning_rate': 0.0002727710843373494, 'epoch': 0.09}\n",
      "{'loss': 2.0888, 'grad_norm': 1.1923140287399292, 'learning_rate': 0.00027253012048192765, 'epoch': 0.1}\n",
      "{'loss': 2.0404, 'grad_norm': 1.3213796615600586, 'learning_rate': 0.000272289156626506, 'epoch': 0.1}\n",
      "{'loss': 2.2255, 'grad_norm': 1.2242929935455322, 'learning_rate': 0.0002720481927710843, 'epoch': 0.1}\n",
      "{'loss': 2.1756, 'grad_norm': 1.3068652153015137, 'learning_rate': 0.0002718072289156626, 'epoch': 0.1}\n",
      "{'loss': 2.1649, 'grad_norm': 1.3374478816986084, 'learning_rate': 0.00027156626506024095, 'epoch': 0.1}\n",
      "{'loss': 1.9271, 'grad_norm': 1.9840441942214966, 'learning_rate': 0.0002713253012048193, 'epoch': 0.1}\n",
      "{'loss': 2.3506, 'grad_norm': 1.3781795501708984, 'learning_rate': 0.0002710843373493976, 'epoch': 0.1}\n",
      "{'loss': 2.1538, 'grad_norm': 1.3787238597869873, 'learning_rate': 0.00027084337349397587, 'epoch': 0.1}\n",
      "{'loss': 1.9914, 'grad_norm': 1.386662483215332, 'learning_rate': 0.0002706024096385542, 'epoch': 0.1}\n",
      "{'loss': 2.2805, 'grad_norm': 1.2812538146972656, 'learning_rate': 0.0002703614457831325, 'epoch': 0.1}\n",
      "{'loss': 1.9808, 'grad_norm': 1.3299665451049805, 'learning_rate': 0.0002701204819277108, 'epoch': 0.1}\n",
      "{'loss': 1.9876, 'grad_norm': 1.3954243659973145, 'learning_rate': 0.0002698795180722891, 'epoch': 0.1}\n",
      "{'loss': 2.2065, 'grad_norm': 1.1640206575393677, 'learning_rate': 0.00026963855421686744, 'epoch': 0.1}\n",
      "{'loss': 1.9822, 'grad_norm': 1.2194746732711792, 'learning_rate': 0.00026939759036144576, 'epoch': 0.11}\n",
      "{'loss': 2.2253, 'grad_norm': 1.3839471340179443, 'learning_rate': 0.0002691566265060241, 'epoch': 0.11}\n",
      "{'loss': 2.2503, 'grad_norm': 1.398749589920044, 'learning_rate': 0.0002689156626506024, 'epoch': 0.11}\n",
      "{'loss': 2.157, 'grad_norm': 1.6370288133621216, 'learning_rate': 0.00026867469879518073, 'epoch': 0.11}\n",
      "{'loss': 2.0655, 'grad_norm': 1.2901101112365723, 'learning_rate': 0.000268433734939759, 'epoch': 0.11}\n",
      "{'loss': 2.057, 'grad_norm': 1.6934727430343628, 'learning_rate': 0.00026819277108433733, 'epoch': 0.11}\n",
      "{'loss': 2.0382, 'grad_norm': 1.6071182489395142, 'learning_rate': 0.00026795180722891565, 'epoch': 0.11}\n",
      "{'loss': 1.8404, 'grad_norm': 1.093794584274292, 'learning_rate': 0.0002677108433734939, 'epoch': 0.11}\n",
      "{'loss': 2.1836, 'grad_norm': 1.4353936910629272, 'learning_rate': 0.00026746987951807225, 'epoch': 0.11}\n",
      "{'loss': 2.1606, 'grad_norm': 1.3198580741882324, 'learning_rate': 0.00026722891566265057, 'epoch': 0.11}\n",
      "{'loss': 2.1361, 'grad_norm': 1.229083776473999, 'learning_rate': 0.0002669879518072289, 'epoch': 0.11}\n",
      "{'loss': 2.0865, 'grad_norm': 1.6433361768722534, 'learning_rate': 0.0002667469879518072, 'epoch': 0.11}\n",
      "{'loss': 2.1651, 'grad_norm': 1.3892978429794312, 'learning_rate': 0.00026650602409638554, 'epoch': 0.12}\n",
      "{'loss': 2.1556, 'grad_norm': 1.2881977558135986, 'learning_rate': 0.00026626506024096387, 'epoch': 0.12}\n",
      "{'loss': 1.9306, 'grad_norm': 1.1597970724105835, 'learning_rate': 0.00026602409638554214, 'epoch': 0.12}\n",
      "{'loss': 2.2355, 'grad_norm': 1.4557548761367798, 'learning_rate': 0.00026578313253012046, 'epoch': 0.12}\n",
      "{'loss': 2.2168, 'grad_norm': 1.5636485815048218, 'learning_rate': 0.0002655421686746988, 'epoch': 0.12}\n",
      "{'loss': 2.2876, 'grad_norm': 1.1592144966125488, 'learning_rate': 0.00026530120481927706, 'epoch': 0.12}\n",
      "{'loss': 2.2697, 'grad_norm': 1.4841821193695068, 'learning_rate': 0.0002650602409638554, 'epoch': 0.12}\n",
      "{'loss': 2.0962, 'grad_norm': 1.53982412815094, 'learning_rate': 0.0002648192771084337, 'epoch': 0.12}\n",
      "{'loss': 2.2872, 'grad_norm': 1.1497690677642822, 'learning_rate': 0.00026457831325301203, 'epoch': 0.12}\n",
      "{'loss': 2.2777, 'grad_norm': 1.4599034786224365, 'learning_rate': 0.00026433734939759036, 'epoch': 0.12}\n",
      "{'loss': 1.9172, 'grad_norm': 1.3122690916061401, 'learning_rate': 0.0002640963855421687, 'epoch': 0.12}\n",
      "{'loss': 2.0809, 'grad_norm': 1.1369556188583374, 'learning_rate': 0.00026385542168674695, 'epoch': 0.12}\n",
      "{'loss': 2.2467, 'grad_norm': 1.2337712049484253, 'learning_rate': 0.0002636144578313253, 'epoch': 0.12}\n",
      "{'loss': 2.1912, 'grad_norm': 1.2149240970611572, 'learning_rate': 0.0002633734939759036, 'epoch': 0.13}\n",
      "{'loss': 1.9883, 'grad_norm': 1.8029910326004028, 'learning_rate': 0.0002631325301204819, 'epoch': 0.13}\n",
      "{'loss': 2.1693, 'grad_norm': 1.3056505918502808, 'learning_rate': 0.0002628915662650602, 'epoch': 0.13}\n",
      "{'loss': 2.0362, 'grad_norm': 1.3038219213485718, 'learning_rate': 0.0002626506024096385, 'epoch': 0.13}\n",
      "{'loss': 2.2326, 'grad_norm': 1.2225756645202637, 'learning_rate': 0.00026240963855421684, 'epoch': 0.13}\n",
      "{'loss': 2.0192, 'grad_norm': 1.754570722579956, 'learning_rate': 0.00026216867469879517, 'epoch': 0.13}\n",
      "{'loss': 2.2968, 'grad_norm': 1.3244903087615967, 'learning_rate': 0.0002619277108433735, 'epoch': 0.13}\n",
      "{'loss': 1.893, 'grad_norm': 1.6570816040039062, 'learning_rate': 0.0002616867469879518, 'epoch': 0.13}\n",
      "{'loss': 2.3493, 'grad_norm': 1.244344711303711, 'learning_rate': 0.0002614457831325301, 'epoch': 0.13}\n",
      "{'loss': 2.1137, 'grad_norm': 1.5432151556015015, 'learning_rate': 0.0002612048192771084, 'epoch': 0.13}\n",
      "{'loss': 2.3306, 'grad_norm': 1.4551185369491577, 'learning_rate': 0.00026096385542168673, 'epoch': 0.13}\n",
      "{'loss': 1.9769, 'grad_norm': 1.4808639287948608, 'learning_rate': 0.00026072289156626506, 'epoch': 0.13}\n",
      "{'loss': 1.9832, 'grad_norm': 1.2223132848739624, 'learning_rate': 0.00026048192771084333, 'epoch': 0.14}\n",
      "{'loss': 2.1317, 'grad_norm': 1.6705397367477417, 'learning_rate': 0.00026024096385542165, 'epoch': 0.14}\n",
      "{'loss': 2.2321, 'grad_norm': 1.2295430898666382, 'learning_rate': 0.00026, 'epoch': 0.14}\n",
      "{'loss': 2.0166, 'grad_norm': 1.6668838262557983, 'learning_rate': 0.0002597590361445783, 'epoch': 0.14}\n",
      "{'loss': 2.2835, 'grad_norm': 1.248857021331787, 'learning_rate': 0.0002595180722891566, 'epoch': 0.14}\n",
      "{'loss': 2.1006, 'grad_norm': 1.7357231378555298, 'learning_rate': 0.0002592771084337349, 'epoch': 0.14}\n",
      "{'loss': 2.0457, 'grad_norm': 1.3109101057052612, 'learning_rate': 0.0002590361445783132, 'epoch': 0.14}\n",
      "{'loss': 1.9766, 'grad_norm': 1.8336524963378906, 'learning_rate': 0.00025879518072289154, 'epoch': 0.14}\n",
      "{'loss': 2.257, 'grad_norm': 1.2656497955322266, 'learning_rate': 0.00025855421686746987, 'epoch': 0.14}\n",
      "{'loss': 2.3327, 'grad_norm': 1.4106125831604004, 'learning_rate': 0.0002583132530120482, 'epoch': 0.14}\n",
      "{'loss': 2.2466, 'grad_norm': 1.278151273727417, 'learning_rate': 0.00025807228915662646, 'epoch': 0.14}\n",
      "{'loss': 1.6427, 'grad_norm': 1.971517562866211, 'learning_rate': 0.0002578313253012048, 'epoch': 0.14}\n",
      "{'loss': 2.2589, 'grad_norm': 1.3060810565948486, 'learning_rate': 0.0002575903614457831, 'epoch': 0.14}\n",
      "{'loss': 2.0057, 'grad_norm': 1.3184130191802979, 'learning_rate': 0.00025734939759036144, 'epoch': 0.15}\n",
      "{'loss': 2.1004, 'grad_norm': 1.3344682455062866, 'learning_rate': 0.0002571084337349397, 'epoch': 0.15}\n",
      "{'loss': 2.1525, 'grad_norm': 1.3847198486328125, 'learning_rate': 0.00025686746987951803, 'epoch': 0.15}\n",
      "{'loss': 1.8572, 'grad_norm': 1.4634801149368286, 'learning_rate': 0.00025662650602409636, 'epoch': 0.15}\n",
      "{'loss': 2.3153, 'grad_norm': 1.3867288827896118, 'learning_rate': 0.0002563855421686747, 'epoch': 0.15}\n",
      "{'loss': 1.7793, 'grad_norm': 1.8962438106536865, 'learning_rate': 0.000256144578313253, 'epoch': 0.15}\n",
      "{'loss': 1.8414, 'grad_norm': 1.351822018623352, 'learning_rate': 0.00025590361445783133, 'epoch': 0.15}\n",
      "{'loss': 2.2364, 'grad_norm': 1.3579131364822388, 'learning_rate': 0.0002556626506024096, 'epoch': 0.15}\n",
      "{'loss': 2.0884, 'grad_norm': 1.3611860275268555, 'learning_rate': 0.0002554216867469879, 'epoch': 0.15}\n",
      "{'loss': 2.1401, 'grad_norm': 1.3325942754745483, 'learning_rate': 0.00025518072289156625, 'epoch': 0.15}\n",
      "{'loss': 2.1478, 'grad_norm': 1.484565019607544, 'learning_rate': 0.0002549397590361445, 'epoch': 0.15}\n",
      "{'loss': 2.0304, 'grad_norm': 1.4015419483184814, 'learning_rate': 0.00025469879518072284, 'epoch': 0.15}\n",
      "{'loss': 2.205, 'grad_norm': 1.8265299797058105, 'learning_rate': 0.00025445783132530117, 'epoch': 0.16}\n",
      "{'loss': 2.0573, 'grad_norm': 1.6501317024230957, 'learning_rate': 0.0002542168674698795, 'epoch': 0.16}\n",
      "{'loss': 1.8905, 'grad_norm': 1.3039512634277344, 'learning_rate': 0.0002539759036144578, 'epoch': 0.16}\n",
      "{'loss': 2.1556, 'grad_norm': 1.7155060768127441, 'learning_rate': 0.00025373493975903614, 'epoch': 0.16}\n",
      "{'loss': 2.257, 'grad_norm': 1.2818491458892822, 'learning_rate': 0.00025349397590361446, 'epoch': 0.16}\n",
      "{'loss': 2.0752, 'grad_norm': 1.301772952079773, 'learning_rate': 0.00025325301204819273, 'epoch': 0.16}\n",
      "{'loss': 2.0173, 'grad_norm': 1.2562164068222046, 'learning_rate': 0.00025301204819277106, 'epoch': 0.16}\n",
      "{'loss': 2.2391, 'grad_norm': 1.633162260055542, 'learning_rate': 0.0002527710843373494, 'epoch': 0.16}\n",
      "{'loss': 2.2712, 'grad_norm': 1.9570189714431763, 'learning_rate': 0.00025253012048192765, 'epoch': 0.16}\n",
      "{'loss': 1.7468, 'grad_norm': 1.298793077468872, 'learning_rate': 0.000252289156626506, 'epoch': 0.16}\n",
      "{'loss': 1.852, 'grad_norm': 1.7255876064300537, 'learning_rate': 0.0002520481927710843, 'epoch': 0.16}\n",
      "{'loss': 2.2282, 'grad_norm': 1.4030290842056274, 'learning_rate': 0.0002518072289156626, 'epoch': 0.16}\n",
      "{'loss': 1.861, 'grad_norm': 1.3359731435775757, 'learning_rate': 0.00025156626506024095, 'epoch': 0.16}\n",
      "{'loss': 2.2722, 'grad_norm': 1.3606959581375122, 'learning_rate': 0.0002513253012048193, 'epoch': 0.17}\n",
      "{'loss': 2.3276, 'grad_norm': 1.750308871269226, 'learning_rate': 0.0002510843373493976, 'epoch': 0.17}\n",
      "{'loss': 2.0717, 'grad_norm': 1.2990590333938599, 'learning_rate': 0.00025084337349397587, 'epoch': 0.17}\n",
      "{'loss': 2.2803, 'grad_norm': 1.34334397315979, 'learning_rate': 0.0002506024096385542, 'epoch': 0.17}\n",
      "{'loss': 1.7544, 'grad_norm': 1.4871907234191895, 'learning_rate': 0.0002503614457831325, 'epoch': 0.17}\n",
      "{'loss': 2.1595, 'grad_norm': 1.2871583700180054, 'learning_rate': 0.0002501204819277108, 'epoch': 0.17}\n",
      "{'loss': 2.1746, 'grad_norm': 1.3797434568405151, 'learning_rate': 0.0002498795180722891, 'epoch': 0.17}\n",
      "{'loss': 2.1452, 'grad_norm': 1.6175060272216797, 'learning_rate': 0.00024963855421686744, 'epoch': 0.17}\n",
      "{'loss': 1.9978, 'grad_norm': 1.791658878326416, 'learning_rate': 0.00024939759036144576, 'epoch': 0.17}\n",
      "{'loss': 2.2656, 'grad_norm': 1.2550359964370728, 'learning_rate': 0.0002491566265060241, 'epoch': 0.17}\n",
      "{'loss': 2.2307, 'grad_norm': 2.174762487411499, 'learning_rate': 0.0002489156626506024, 'epoch': 0.17}\n",
      "{'loss': 2.287, 'grad_norm': 1.2327409982681274, 'learning_rate': 0.00024867469879518074, 'epoch': 0.17}\n",
      "{'loss': 1.7273, 'grad_norm': 1.8686702251434326, 'learning_rate': 0.000248433734939759, 'epoch': 0.18}\n",
      "{'loss': 2.0083, 'grad_norm': 1.361049771308899, 'learning_rate': 0.00024819277108433733, 'epoch': 0.18}\n",
      "{'loss': 2.249, 'grad_norm': 1.444855809211731, 'learning_rate': 0.00024795180722891565, 'epoch': 0.18}\n",
      "{'loss': 2.1321, 'grad_norm': 1.4271608591079712, 'learning_rate': 0.0002477108433734939, 'epoch': 0.18}\n",
      "{'loss': 2.1598, 'grad_norm': 1.8344780206680298, 'learning_rate': 0.00024746987951807225, 'epoch': 0.18}\n",
      "{'loss': 1.8592, 'grad_norm': 1.485177755355835, 'learning_rate': 0.0002472289156626506, 'epoch': 0.18}\n",
      "{'loss': 2.0569, 'grad_norm': 1.6483204364776611, 'learning_rate': 0.0002469879518072289, 'epoch': 0.18}\n",
      "{'loss': 2.0723, 'grad_norm': 1.3960919380187988, 'learning_rate': 0.0002467469879518072, 'epoch': 0.18}\n",
      "{'loss': 1.9568, 'grad_norm': 1.4595707654953003, 'learning_rate': 0.00024650602409638555, 'epoch': 0.18}\n",
      "{'loss': 2.2474, 'grad_norm': 1.4882278442382812, 'learning_rate': 0.0002462650602409638, 'epoch': 0.18}\n",
      "{'loss': 2.2811, 'grad_norm': 1.4553534984588623, 'learning_rate': 0.00024602409638554214, 'epoch': 0.18}\n",
      "{'loss': 2.1069, 'grad_norm': 1.5240273475646973, 'learning_rate': 0.00024578313253012046, 'epoch': 0.18}\n",
      "{'loss': 2.204, 'grad_norm': 1.5791988372802734, 'learning_rate': 0.0002455421686746988, 'epoch': 0.18}\n",
      "{'loss': 2.0617, 'grad_norm': 1.4877525568008423, 'learning_rate': 0.00024530120481927706, 'epoch': 0.19}\n",
      "{'loss': 1.9206, 'grad_norm': 1.3874013423919678, 'learning_rate': 0.0002450602409638554, 'epoch': 0.19}\n",
      "{'loss': 2.3408, 'grad_norm': 1.7630153894424438, 'learning_rate': 0.0002448192771084337, 'epoch': 0.19}\n",
      "{'loss': 2.296, 'grad_norm': 1.3433423042297363, 'learning_rate': 0.00024457831325301203, 'epoch': 0.19}\n",
      "{'loss': 1.9165, 'grad_norm': 1.4551289081573486, 'learning_rate': 0.00024433734939759036, 'epoch': 0.19}\n",
      "{'loss': 2.1861, 'grad_norm': 1.2840709686279297, 'learning_rate': 0.00024409638554216863, 'epoch': 0.19}\n",
      "{'loss': 2.1673, 'grad_norm': 1.3264472484588623, 'learning_rate': 0.00024385542168674695, 'epoch': 0.19}\n",
      "{'loss': 2.2031, 'grad_norm': 1.5419831275939941, 'learning_rate': 0.00024361445783132528, 'epoch': 0.19}\n",
      "{'loss': 2.1263, 'grad_norm': 1.2648653984069824, 'learning_rate': 0.0002433734939759036, 'epoch': 0.19}\n",
      "{'loss': 2.0999, 'grad_norm': 1.220759630203247, 'learning_rate': 0.0002431325301204819, 'epoch': 0.19}\n",
      "{'loss': 2.288, 'grad_norm': 1.5233259201049805, 'learning_rate': 0.00024289156626506022, 'epoch': 0.19}\n",
      "{'loss': 1.9366, 'grad_norm': 1.6422619819641113, 'learning_rate': 0.00024265060240963855, 'epoch': 0.19}\n",
      "{'loss': 2.2281, 'grad_norm': 1.4329460859298706, 'learning_rate': 0.00024240963855421684, 'epoch': 0.2}\n",
      "{'loss': 1.9406, 'grad_norm': 1.2348870038986206, 'learning_rate': 0.00024216867469879517, 'epoch': 0.2}\n",
      "{'loss': 2.142, 'grad_norm': 1.6167134046554565, 'learning_rate': 0.00024192771084337347, 'epoch': 0.2}\n",
      "{'loss': 2.0162, 'grad_norm': 1.400015115737915, 'learning_rate': 0.00024168674698795176, 'epoch': 0.2}\n",
      "{'loss': 2.2685, 'grad_norm': 1.7636059522628784, 'learning_rate': 0.0002414457831325301, 'epoch': 0.2}\n",
      "{'loss': 2.1514, 'grad_norm': 1.322823166847229, 'learning_rate': 0.0002412048192771084, 'epoch': 0.2}\n",
      "{'loss': 1.8054, 'grad_norm': 1.4360889196395874, 'learning_rate': 0.00024096385542168674, 'epoch': 0.2}\n",
      "{'loss': 2.1684, 'grad_norm': 1.8332202434539795, 'learning_rate': 0.00024072289156626503, 'epoch': 0.2}\n",
      "{'loss': 2.1961, 'grad_norm': 1.2577745914459229, 'learning_rate': 0.00024048192771084336, 'epoch': 0.2}\n",
      "{'loss': 2.056, 'grad_norm': 1.6317909955978394, 'learning_rate': 0.00024024096385542168, 'epoch': 0.2}\n",
      "{'loss': 1.9818, 'grad_norm': 1.5796910524368286, 'learning_rate': 0.00023999999999999998, 'epoch': 0.2}\n",
      "{'loss': 1.7585, 'grad_norm': 1.5878057479858398, 'learning_rate': 0.00023975903614457828, 'epoch': 0.2}\n",
      "{'loss': 2.0206, 'grad_norm': 1.3899348974227905, 'learning_rate': 0.0002395180722891566, 'epoch': 0.2}\n",
      "{'loss': 1.988, 'grad_norm': 1.467415690422058, 'learning_rate': 0.0002392771084337349, 'epoch': 0.21}\n",
      "{'loss': 2.1882, 'grad_norm': 1.529462456703186, 'learning_rate': 0.00023903614457831322, 'epoch': 0.21}\n",
      "{'loss': 1.9992, 'grad_norm': 1.5999476909637451, 'learning_rate': 0.00023879518072289155, 'epoch': 0.21}\n",
      "{'loss': 2.2056, 'grad_norm': 1.8929686546325684, 'learning_rate': 0.00023855421686746987, 'epoch': 0.21}\n",
      "{'loss': 2.2411, 'grad_norm': 1.499593734741211, 'learning_rate': 0.00023831325301204817, 'epoch': 0.21}\n",
      "{'loss': 2.2592, 'grad_norm': 1.2468305826187134, 'learning_rate': 0.0002380722891566265, 'epoch': 0.21}\n",
      "{'loss': 2.0526, 'grad_norm': 1.4838873147964478, 'learning_rate': 0.00023783132530120482, 'epoch': 0.21}\n",
      "{'loss': 2.2513, 'grad_norm': 1.4434881210327148, 'learning_rate': 0.0002375903614457831, 'epoch': 0.21}\n",
      "{'loss': 2.2754, 'grad_norm': 1.5363444089889526, 'learning_rate': 0.0002373493975903614, 'epoch': 0.21}\n",
      "{'loss': 1.8518, 'grad_norm': 1.6742298603057861, 'learning_rate': 0.00023710843373493974, 'epoch': 0.21}\n",
      "{'loss': 2.1772, 'grad_norm': 1.2126874923706055, 'learning_rate': 0.00023686746987951803, 'epoch': 0.21}\n",
      "{'loss': 2.2544, 'grad_norm': 1.5931434631347656, 'learning_rate': 0.00023662650602409636, 'epoch': 0.21}\n",
      "{'loss': 2.1464, 'grad_norm': 1.4991849660873413, 'learning_rate': 0.00023638554216867468, 'epoch': 0.22}\n",
      "{'loss': 1.9683, 'grad_norm': 1.3770023584365845, 'learning_rate': 0.000236144578313253, 'epoch': 0.22}\n",
      "{'loss': 1.9241, 'grad_norm': 1.6096123456954956, 'learning_rate': 0.0002359036144578313, 'epoch': 0.22}\n",
      "{'loss': 2.2819, 'grad_norm': 1.4300804138183594, 'learning_rate': 0.00023566265060240963, 'epoch': 0.22}\n",
      "{'loss': 2.0457, 'grad_norm': 1.4528900384902954, 'learning_rate': 0.00023542168674698795, 'epoch': 0.22}\n",
      "{'loss': 2.2866, 'grad_norm': 1.5084905624389648, 'learning_rate': 0.00023518072289156622, 'epoch': 0.22}\n",
      "{'loss': 2.0976, 'grad_norm': 1.446255087852478, 'learning_rate': 0.00023493975903614455, 'epoch': 0.22}\n",
      "{'loss': 2.0812, 'grad_norm': 1.4041332006454468, 'learning_rate': 0.00023469879518072287, 'epoch': 0.22}\n",
      "{'loss': 2.0646, 'grad_norm': 1.6494901180267334, 'learning_rate': 0.00023445783132530117, 'epoch': 0.22}\n",
      "{'loss': 1.8565, 'grad_norm': 1.3277515172958374, 'learning_rate': 0.0002342168674698795, 'epoch': 0.22}\n",
      "{'loss': 2.2861, 'grad_norm': 1.4800612926483154, 'learning_rate': 0.00023397590361445782, 'epoch': 0.22}\n",
      "{'loss': 2.2498, 'grad_norm': 1.5041615962982178, 'learning_rate': 0.00023373493975903614, 'epoch': 0.22}\n",
      "{'loss': 1.9123, 'grad_norm': 1.7279433012008667, 'learning_rate': 0.00023349397590361444, 'epoch': 0.22}\n",
      "{'loss': 1.9895, 'grad_norm': 1.4778664112091064, 'learning_rate': 0.00023325301204819276, 'epoch': 0.23}\n",
      "{'loss': 2.1784, 'grad_norm': 1.6508581638336182, 'learning_rate': 0.00023301204819277106, 'epoch': 0.23}\n",
      "{'loss': 2.1603, 'grad_norm': 1.512863278388977, 'learning_rate': 0.00023277108433734936, 'epoch': 0.23}\n",
      "{'loss': 2.1321, 'grad_norm': 1.5844441652297974, 'learning_rate': 0.00023253012048192768, 'epoch': 0.23}\n",
      "{'loss': 2.1766, 'grad_norm': 1.484938144683838, 'learning_rate': 0.000232289156626506, 'epoch': 0.23}\n",
      "{'loss': 1.9759, 'grad_norm': 1.4715121984481812, 'learning_rate': 0.00023204819277108433, 'epoch': 0.23}\n",
      "{'loss': 2.1775, 'grad_norm': 1.42014479637146, 'learning_rate': 0.00023180722891566263, 'epoch': 0.23}\n",
      "{'loss': 2.1594, 'grad_norm': 1.5673062801361084, 'learning_rate': 0.00023156626506024095, 'epoch': 0.23}\n",
      "{'loss': 1.9515, 'grad_norm': 1.6306763887405396, 'learning_rate': 0.00023132530120481928, 'epoch': 0.23}\n",
      "{'loss': 2.1282, 'grad_norm': 1.5898208618164062, 'learning_rate': 0.00023108433734939757, 'epoch': 0.23}\n",
      "{'loss': 2.1231, 'grad_norm': 1.5006855726242065, 'learning_rate': 0.00023084337349397587, 'epoch': 0.23}\n",
      "{'loss': 2.2326, 'grad_norm': 1.5426709651947021, 'learning_rate': 0.0002306024096385542, 'epoch': 0.23}\n",
      "{'loss': 2.0033, 'grad_norm': 1.4493476152420044, 'learning_rate': 0.0002303614457831325, 'epoch': 0.24}\n",
      "{'loss': 2.3864, 'grad_norm': 1.4264603853225708, 'learning_rate': 0.00023012048192771082, 'epoch': 0.24}\n",
      "{'loss': 2.0311, 'grad_norm': 1.4383703470230103, 'learning_rate': 0.00022987951807228914, 'epoch': 0.24}\n",
      "{'loss': 1.8928, 'grad_norm': 1.7944471836090088, 'learning_rate': 0.00022963855421686747, 'epoch': 0.24}\n",
      "{'loss': 2.0897, 'grad_norm': 1.745436429977417, 'learning_rate': 0.00022939759036144576, 'epoch': 0.24}\n",
      "{'loss': 2.0449, 'grad_norm': 1.436782956123352, 'learning_rate': 0.0002291566265060241, 'epoch': 0.24}\n",
      "{'loss': 1.9809, 'grad_norm': 1.5490589141845703, 'learning_rate': 0.0002289156626506024, 'epoch': 0.24}\n",
      "{'loss': 2.1887, 'grad_norm': 1.543381690979004, 'learning_rate': 0.00022867469879518068, 'epoch': 0.24}\n",
      "{'loss': 1.9645, 'grad_norm': 1.3461217880249023, 'learning_rate': 0.000228433734939759, 'epoch': 0.24}\n",
      "{'loss': 2.0838, 'grad_norm': 1.7751123905181885, 'learning_rate': 0.00022819277108433733, 'epoch': 0.24}\n",
      "{'loss': 2.186, 'grad_norm': 1.4057918787002563, 'learning_rate': 0.00022795180722891563, 'epoch': 0.24}\n",
      "{'loss': 2.0561, 'grad_norm': 1.4038352966308594, 'learning_rate': 0.00022771084337349395, 'epoch': 0.24}\n",
      "{'loss': 1.6567, 'grad_norm': 1.710335612297058, 'learning_rate': 0.00022746987951807228, 'epoch': 0.24}\n",
      "{'loss': 2.1621, 'grad_norm': 1.3987882137298584, 'learning_rate': 0.0002272289156626506, 'epoch': 0.25}\n",
      "{'loss': 2.033, 'grad_norm': 1.8084700107574463, 'learning_rate': 0.0002269879518072289, 'epoch': 0.25}\n",
      "{'loss': 2.2269, 'grad_norm': 1.582808256149292, 'learning_rate': 0.00022674698795180722, 'epoch': 0.25}\n",
      "{'loss': 2.1773, 'grad_norm': 1.431134819984436, 'learning_rate': 0.00022650602409638552, 'epoch': 0.25}\n",
      "{'loss': 2.2686, 'grad_norm': 1.1485775709152222, 'learning_rate': 0.00022626506024096382, 'epoch': 0.25}\n",
      "{'loss': 2.0483, 'grad_norm': 1.447627305984497, 'learning_rate': 0.00022602409638554214, 'epoch': 0.25}\n",
      "{'loss': 2.1957, 'grad_norm': 1.7904514074325562, 'learning_rate': 0.00022578313253012047, 'epoch': 0.25}\n",
      "{'loss': 2.066, 'grad_norm': 1.4321837425231934, 'learning_rate': 0.00022554216867469876, 'epoch': 0.25}\n",
      "{'loss': 2.0792, 'grad_norm': 1.3921271562576294, 'learning_rate': 0.0002253012048192771, 'epoch': 0.25}\n",
      "{'loss': 2.2806, 'grad_norm': 1.589003324508667, 'learning_rate': 0.0002250602409638554, 'epoch': 0.25}\n",
      "{'loss': 2.4978, 'grad_norm': 1.285584568977356, 'learning_rate': 0.00022481927710843374, 'epoch': 0.25}\n",
      "{'loss': 1.9339, 'grad_norm': 1.5426194667816162, 'learning_rate': 0.00022457831325301203, 'epoch': 0.25}\n",
      "{'loss': 2.1797, 'grad_norm': 1.44038724899292, 'learning_rate': 0.00022433734939759033, 'epoch': 0.26}\n",
      "{'loss': 2.3913, 'grad_norm': 1.380224585533142, 'learning_rate': 0.00022409638554216866, 'epoch': 0.26}\n",
      "{'loss': 2.258, 'grad_norm': 1.3551616668701172, 'learning_rate': 0.00022385542168674695, 'epoch': 0.26}\n",
      "{'loss': 2.3164, 'grad_norm': 1.337654948234558, 'learning_rate': 0.00022361445783132528, 'epoch': 0.26}\n",
      "{'loss': 2.0876, 'grad_norm': 1.5111867189407349, 'learning_rate': 0.0002233734939759036, 'epoch': 0.26}\n",
      "{'loss': 2.2288, 'grad_norm': 1.2726126909255981, 'learning_rate': 0.0002231325301204819, 'epoch': 0.26}\n",
      "{'loss': 2.2349, 'grad_norm': 1.5392781496047974, 'learning_rate': 0.00022289156626506022, 'epoch': 0.26}\n",
      "{'loss': 2.1883, 'grad_norm': 1.8476685285568237, 'learning_rate': 0.00022265060240963855, 'epoch': 0.26}\n",
      "{'loss': 2.1382, 'grad_norm': 1.6374409198760986, 'learning_rate': 0.00022240963855421687, 'epoch': 0.26}\n",
      "{'loss': 1.9676, 'grad_norm': 1.338687777519226, 'learning_rate': 0.00022216867469879514, 'epoch': 0.26}\n",
      "{'loss': 2.2688, 'grad_norm': 1.3167766332626343, 'learning_rate': 0.00022192771084337347, 'epoch': 0.26}\n",
      "{'loss': 2.0092, 'grad_norm': 1.5680041313171387, 'learning_rate': 0.0002216867469879518, 'epoch': 0.26}\n",
      "{'loss': 2.151, 'grad_norm': 1.5255385637283325, 'learning_rate': 0.0002214457831325301, 'epoch': 0.26}\n",
      "{'loss': 2.0347, 'grad_norm': 1.3381439447402954, 'learning_rate': 0.0002212048192771084, 'epoch': 0.27}\n",
      "{'loss': 1.9521, 'grad_norm': 1.3928747177124023, 'learning_rate': 0.00022096385542168674, 'epoch': 0.27}\n",
      "{'loss': 1.6583, 'grad_norm': 1.143331527709961, 'learning_rate': 0.00022072289156626503, 'epoch': 0.27}\n",
      "{'loss': 2.1041, 'grad_norm': 1.7278316020965576, 'learning_rate': 0.00022048192771084336, 'epoch': 0.27}\n",
      "{'loss': 2.2295, 'grad_norm': 1.4926220178604126, 'learning_rate': 0.00022024096385542168, 'epoch': 0.27}\n",
      "{'loss': 1.9203, 'grad_norm': 2.078425168991089, 'learning_rate': 0.00021999999999999995, 'epoch': 0.27}\n",
      "{'loss': 2.1909, 'grad_norm': 1.9885404109954834, 'learning_rate': 0.00021975903614457828, 'epoch': 0.27}\n",
      "{'loss': 2.0047, 'grad_norm': 1.43980872631073, 'learning_rate': 0.0002195180722891566, 'epoch': 0.27}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:145\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m<string>:368\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.print_final_memory_usage(start_gpu_memory, max_memory, trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do modelo depois do treinamento\n",
    "\n",
    "df = dataset.to_pandas().sample(frac=1).head(5).copy()\n",
    "for _, row in df.iterrows():\n",
    "  title = row['title']\n",
    "  print(f\"Resultado da predi√ß√£o para o t√≠tulo: [{title}]\\n\")\n",
    "  helper.predict_text_streamer(model, tokenizer, title)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('Meta-Llama-3.1-8B') # Local saving\n",
    "tokenizer.save_pretrained('Meta-Llama-3.1-8B')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
