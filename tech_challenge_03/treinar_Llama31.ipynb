{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ambiente configurado para treinamento local em um PC com Placa de V√≠deo Nvidia RTX-3060 12GB\n",
    "\n",
    "## Utilizando miniconda, instalado em um Linux Ubuntu conforme orienta√ß√µes do link: https://docs.anaconda.com/miniconda/\n",
    "## Utilizando miniconda para cria√ß√£o do ambiente do unsloth conforme orienta√ß√£o no link: https://docs.unsloth.ai/get-started/installation/conda-install\n",
    "\n",
    "## >> Para configurar o ambiente, remova o coment√°rio (\"##\") e execute os comandos. Lembre-se de instalar o miniconda previamente\n",
    "\n",
    "#!pip install nbformat\n",
    "#!conda install -c conda-forge ipywidgets\n",
    "#!conda create --name unsloth_env python=3.10 pytorch-cuda=12.1 pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers -y\n",
    "#!conda activate unsloth_env\n",
    "#!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "#!pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "2.4.1\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "import torch \n",
    "import pandas as pd\n",
    "\n",
    "import datasets\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id Model: 2 - Model Name: unsloth/Meta-Llama-3.1-8B-bnb-4bit\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "model_name, raw_model, tokenizer = helper.get_model_by_id(2, max_seq_length, dtype, load_in_4bit)  ## \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func_train(examples):        \n",
    "    inputs       = examples['title']\n",
    "    outputs      = examples['content']\n",
    "    texts = []\n",
    "    #for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = helper.alpaca_prompt.format(input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = helper.get_fast_language_model(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280f65f6143943439a24cf86352052c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68884a921a864a2eb650c25916bffd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content', 'text'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_csv('../data/trn_sample.csv', sep=';', nrows=100)\n",
    "dataset = dataset.map(formatting_prompts_func_train, batched = True,)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb532340c09b49a0bcbfced1ab2d6aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 2, # Set this for 1 full training run.\n",
    "        #max_steps = 60,\n",
    "        #learning_rate = 2e-4,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3060. Max memory = 11.65 GB.\n",
      "5.984 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "start_gpu_memory, max_memory = helper.print_start_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 100 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 24\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47f24ba53db494d927e77b273fd7699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9238, 'grad_norm': 5.992072582244873, 'learning_rate': 4e-05, 'epoch': 0.08}\n",
      "{'loss': 3.0795, 'grad_norm': 3.9728596210479736, 'learning_rate': 8e-05, 'epoch': 0.16}\n",
      "{'loss': 2.9872, 'grad_norm': 3.2877695560455322, 'learning_rate': 0.00012, 'epoch': 0.24}\n",
      "{'loss': 3.0473, 'grad_norm': 3.614825487136841, 'learning_rate': 0.00016, 'epoch': 0.32}\n",
      "{'loss': 2.6963, 'grad_norm': 3.3144521713256836, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
      "{'loss': 2.1205, 'grad_norm': 3.167720317840576, 'learning_rate': 0.00018947368421052632, 'epoch': 0.48}\n",
      "{'loss': 2.0921, 'grad_norm': 3.1012771129608154, 'learning_rate': 0.00017894736842105264, 'epoch': 0.56}\n",
      "{'loss': 2.0548, 'grad_norm': 2.90396785736084, 'learning_rate': 0.00016842105263157895, 'epoch': 0.64}\n",
      "{'loss': 2.0922, 'grad_norm': 2.794199228286743, 'learning_rate': 0.00015789473684210527, 'epoch': 0.72}\n",
      "{'loss': 2.1183, 'grad_norm': 2.486328125, 'learning_rate': 0.00014736842105263158, 'epoch': 0.8}\n",
      "{'loss': 1.8921, 'grad_norm': 1.9841482639312744, 'learning_rate': 0.0001368421052631579, 'epoch': 0.88}\n",
      "{'loss': 2.0371, 'grad_norm': 4.93099308013916, 'learning_rate': 0.0001263157894736842, 'epoch': 0.96}\n",
      "{'loss': 2.0921, 'grad_norm': 3.698920726776123, 'learning_rate': 0.00011578947368421053, 'epoch': 1.04}\n",
      "{'loss': 1.4739, 'grad_norm': 2.4449737071990967, 'learning_rate': 0.00010526315789473685, 'epoch': 1.12}\n",
      "{'loss': 1.5244, 'grad_norm': 1.854699730873108, 'learning_rate': 9.473684210526316e-05, 'epoch': 1.2}\n",
      "{'loss': 1.5116, 'grad_norm': 1.831046223640442, 'learning_rate': 8.421052631578948e-05, 'epoch': 1.28}\n",
      "{'loss': 1.5376, 'grad_norm': 2.18930983543396, 'learning_rate': 7.368421052631579e-05, 'epoch': 1.36}\n",
      "{'loss': 1.8206, 'grad_norm': 1.9983940124511719, 'learning_rate': 6.31578947368421e-05, 'epoch': 1.44}\n",
      "{'loss': 1.309, 'grad_norm': 2.7025723457336426, 'learning_rate': 5.2631578947368424e-05, 'epoch': 1.52}\n",
      "{'loss': 1.501, 'grad_norm': 2.2167444229125977, 'learning_rate': 4.210526315789474e-05, 'epoch': 1.6}\n",
      "{'loss': 1.1299, 'grad_norm': 2.5674362182617188, 'learning_rate': 3.157894736842105e-05, 'epoch': 1.68}\n",
      "{'loss': 1.5128, 'grad_norm': 1.8802984952926636, 'learning_rate': 2.105263157894737e-05, 'epoch': 1.76}\n",
      "{'loss': 1.3776, 'grad_norm': 1.7918721437454224, 'learning_rate': 1.0526315789473684e-05, 'epoch': 1.84}\n",
      "{'loss': 1.879, 'grad_norm': 2.0808560848236084, 'learning_rate': 0.0, 'epoch': 1.92}\n",
      "{'train_runtime': 109.5598, 'train_samples_per_second': 1.825, 'train_steps_per_second': 0.219, 'train_loss': 1.9921083251635234, 'epoch': 1.92}\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.5598 seconds used for training.\n",
      "1.83 minutes used for training.\n",
      "Peak reserved memory = 6.52 GB.\n",
      "Peak reserved memory for training = 0.536 GB.\n",
      "Peak reserved memory % of max memory = 55.966 %.\n",
      "Peak reserved memory for training % of max memory = 4.601 %.\n"
     ]
    }
   ],
   "source": [
    "helper.print_final_memory_usage(start_gpu_memory, max_memory, trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is a book that contains a title and description. \n",
      "\n",
      "###INSTRUCTION:\n",
      "Write a resume description that appropriately corresponds to the title.\n",
      "\n",
      "###TITLE:\n",
      "Operation Fortitude The True Story of the Key Spy Operation of WWII That Saved DDay\n",
      "\n",
      "###DESCRIPTION:\n",
      "A fascinating story that contains a wealth of detail that will appeal to military history buffs and anyone interested in the Second World War. The Times A cracking story of deception and espionage. The Mirror A cracking read. The Mirror<|end_of_text|>\n",
      "\n",
      "\n",
      "<|begin_of_text|>Below is a book that contains a title and description. \n",
      "\n",
      "###INSTRUCTION:\n",
      "Write a resume description that appropriately corresponds to the title.\n",
      "\n",
      "###TITLE:\n",
      "I Miss Mummy The true story of a frightened young girl who is desperate to go home\n",
      "\n",
      "###DESCRIPTION:\n",
      "Cathy Glass was a foster carer for twenty years from 1990. She is now an award winning author and writes her foster carer diary entries in her books. She has three teenage children of her own one of whom was adopted after a longterm foster placement. The names of the children and adults she writes about in her books have been changed to protect their identity.<|end_of_text|>\n",
      "\n",
      "\n",
      "<|begin_of_text|>Below is a book that contains a title and description. \n",
      "\n",
      "###INSTRUCTION:\n",
      "Write a resume description that appropriately corresponds to the title.\n",
      "\n",
      "###TITLE:\n",
      "Secrets of Watercolour Success Collins Artists Studio\n",
      "\n",
      "###DESCRIPTION:\n",
      "Praise for Colin Mitchell and his books The Times A very fine book. The Watercolourist A masterly guide to the use of watercolours. The Guardian. Praise for the Collins Artists Studio series A valuable addition to the bookshelves of any artist. The Artist<|end_of_text|>\n",
      "\n",
      "\n",
      "<|begin_of_text|>Below is a book that contains a title and description. \n",
      "\n",
      "###INSTRUCTION:\n",
      "Write a resume description that appropriately corresponds to the title.\n",
      "\n",
      "###TITLE:\n",
      "The Girl in the Mirror\n",
      "\n",
      "###DESCRIPTION:\n",
      "An inspirational true story of a mother and daughter who finally find each other after thirty years apart A mother and daughter with a painful secret...a daughter desperate to know her mothers true story...a mother who cannot bring herself to tell it. When Helen Westerman was a young girl her mother disappeared without trace. She was told that her mother had left of her own accord and that she didnt want to be a mother anymore. But this didnt make sense to Helen and she was determined to find out the truth. This is the story of how she found her mother and how they came to terms with the truth about the past.<|end_of_text|>\n",
      "\n",
      "\n",
      "<|begin_of_text|>Below is a book that contains a title and description. \n",
      "\n",
      "###INSTRUCTION:\n",
      "Write a resume description that appropriately corresponds to the title.\n",
      "\n",
      "###TITLE:\n",
      "A Christmas Promise\n",
      "\n",
      "###DESCRIPTION:\n",
      "A Christmas Promise is a heartwarming and emotional story of love loss and second chances that will make you believe in the magic of Christmas again. The perfect feelgood read for fans of Cathy Glass Dillys Pony Club and The Christmas Promise.<|end_of_text|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Teste do modelo depois do treinamento\n",
    "\n",
    "df = dataset.to_pandas().sample(frac=1).head(5).copy()\n",
    "for _, row in df.iterrows():\n",
    "  title = row['title']\n",
    "  helper.predict_text_streamer(model, tokenizer, title)\n",
    "  print('\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meta-Llama-3.1-8B-bnb-4bit'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Meta-Llama-3.1-8B-bnb-4bit/tokenizer_config.json',\n",
       " 'Meta-Llama-3.1-8B-bnb-4bit/special_tokens_map.json',\n",
       " 'Meta-Llama-3.1-8B-bnb-4bit/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(model_name.split('/')[1]) # Local saving\n",
    "tokenizer.save_pretrained(model_name.split('/')[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
